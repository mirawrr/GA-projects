{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb6300e8",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Project 3: Subreddit Classifier - Tea or Coffee?\n",
    "By Amira (DSI-28)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdb861e",
   "metadata": {},
   "source": [
    "---\n",
    "# Problem Statement\n",
    "\n",
    "We are a team of data scientists working for Coffea Vibes, a beverage company. The company is venturing into e-commerce and will be launching its own website/application selling coffee and tea products to consumers. We have been tasked to build a classification model that can accurately distinguish between coffee and tea in textual data.\n",
    "\n",
    "Our classification model will contribute to the following use cases:\n",
    "\n",
    "1. Our web development team can optimise the recommender systems so as to accurately suggest related products and advertisements to our potential consumers who might have varying preferences for coffee or tea.\n",
    "2. Our business insights team can leverage on the classification model to correctly distinguish customer feedback on coffee and tea (e.g. through emails) and comments made on the company's social media pages, to aid better understanding of customer's feedback and take appropriate actions quickly, if necessary.\n",
    "\n",
    "We evaluated the models based on the following criteria:\n",
    "\n",
    "1. Accuracy scores (the higher, the better)\n",
    "2. Delta between train and test scores (the smaller, the better)\n",
    "3. Clear distinction of important features i.e. words to distinguish coffee and tea"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c4386d",
   "metadata": {},
   "source": [
    "---\n",
    "# Structure\n",
    "\n",
    "To organise my work better, I have organised this project into three notebooks: \n",
    "\n",
    "* Notebook 1 : Data Acquisition\n",
    "* Notebook 2: Data Cleaning & Exploratory Data Analysis\n",
    "* Notebook 3: Modelling & Model Evaluation\n",
    "\n",
    "<span style='color:red'>**This is Notebook 1.**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acac43e9",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: Data Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26983c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries/packages\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.options.display.max_rows = 500\n",
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb7c1331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defined a function that requires input of subreddit name. \n",
    "# this function will perform a for loop for x times to scrape reddit submission posts (100 posts each time).\n",
    "\n",
    "def my_webscraper(subreddit,loops=20):\n",
    "\n",
    "    data = pd.DataFrame() # create an empty dataframe which will store all the scraped data\n",
    "    url = 'https://api.pushshift.io/reddit/search/submission'\n",
    "\n",
    "    for i in range(loops): # range is 10 bc i want to repeat this 10 times (each time pull only 100 posts), can change to other numbers. \n",
    "        if i == 0: # for the first time, 'before' param  will take the most recent value as of when this code is run. \n",
    "            params = {'subreddit' :str(subreddit),'size' : 100}\n",
    "        else: # for the subsequent runs,  change 'before' to the 'created_utc' value of the prev scraped set. \n",
    "            params = {'subreddit' :str(subreddit),'size' : 100,'before' : bef}\n",
    "\n",
    "        # the set of codes below will repeat for each iteration of i. \n",
    "        res = requests.get(url,params)\n",
    "        results = res.json()\n",
    "        posts = pd.DataFrame(results['data'])\n",
    "        bef = posts.iloc[-1]['created_utc']\n",
    "        data = data.append(posts,ignore_index=True)\n",
    "        print(f'This is iteration no. {i+1}, status code is {res.status_code}, accumulated no. of rows extracted is {len(data)}.')\n",
    "        time.sleep(5) # set a timer between each iteration of i.\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a22a7ff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is iteration no. 1, status code is 200, accumulated no. of rows extracted is 100.\n",
      "This is iteration no. 2, status code is 200, accumulated no. of rows extracted is 200.\n",
      "This is iteration no. 3, status code is 200, accumulated no. of rows extracted is 300.\n",
      "This is iteration no. 4, status code is 200, accumulated no. of rows extracted is 400.\n",
      "This is iteration no. 5, status code is 200, accumulated no. of rows extracted is 500.\n",
      "This is iteration no. 6, status code is 200, accumulated no. of rows extracted is 600.\n",
      "This is iteration no. 7, status code is 200, accumulated no. of rows extracted is 700.\n",
      "This is iteration no. 8, status code is 200, accumulated no. of rows extracted is 800.\n",
      "This is iteration no. 9, status code is 200, accumulated no. of rows extracted is 900.\n",
      "This is iteration no. 10, status code is 200, accumulated no. of rows extracted is 1000.\n",
      "This is iteration no. 11, status code is 200, accumulated no. of rows extracted is 1100.\n",
      "This is iteration no. 12, status code is 200, accumulated no. of rows extracted is 1200.\n",
      "This is iteration no. 13, status code is 200, accumulated no. of rows extracted is 1300.\n",
      "This is iteration no. 14, status code is 200, accumulated no. of rows extracted is 1400.\n",
      "This is iteration no. 15, status code is 200, accumulated no. of rows extracted is 1500.\n",
      "This is iteration no. 16, status code is 200, accumulated no. of rows extracted is 1600.\n",
      "This is iteration no. 17, status code is 200, accumulated no. of rows extracted is 1700.\n",
      "This is iteration no. 18, status code is 200, accumulated no. of rows extracted is 1800.\n",
      "This is iteration no. 19, status code is 200, accumulated no. of rows extracted is 1900.\n",
      "This is iteration no. 20, status code is 200, accumulated no. of rows extracted is 2000.\n",
      "(2000, 81)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 81 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   all_awardings                  2000 non-null   object \n",
      " 1   allow_live_comments            2000 non-null   bool   \n",
      " 2   author                         2000 non-null   object \n",
      " 3   author_flair_css_class         0 non-null      object \n",
      " 4   author_flair_richtext          1996 non-null   object \n",
      " 5   author_flair_text              101 non-null    object \n",
      " 6   author_flair_type              1996 non-null   object \n",
      " 7   author_fullname                1996 non-null   object \n",
      " 8   author_is_blocked              2000 non-null   bool   \n",
      " 9   author_patreon_flair           1996 non-null   object \n",
      " 10  author_premium                 1996 non-null   object \n",
      " 11  awarders                       2000 non-null   object \n",
      " 12  can_mod_post                   2000 non-null   bool   \n",
      " 13  contest_mode                   2000 non-null   bool   \n",
      " 14  created_utc                    2000 non-null   int64  \n",
      " 15  domain                         2000 non-null   object \n",
      " 16  full_link                      2000 non-null   object \n",
      " 17  gildings                       2000 non-null   object \n",
      " 18  id                             2000 non-null   object \n",
      " 19  is_created_from_ads_ui         2000 non-null   bool   \n",
      " 20  is_crosspostable               2000 non-null   bool   \n",
      " 21  is_meta                        2000 non-null   bool   \n",
      " 22  is_original_content            2000 non-null   bool   \n",
      " 23  is_reddit_media_domain         2000 non-null   bool   \n",
      " 24  is_robot_indexable             2000 non-null   bool   \n",
      " 25  is_self                        2000 non-null   bool   \n",
      " 26  is_video                       2000 non-null   bool   \n",
      " 27  link_flair_background_color    2000 non-null   object \n",
      " 28  link_flair_richtext            2000 non-null   object \n",
      " 29  link_flair_text_color          2000 non-null   object \n",
      " 30  link_flair_type                2000 non-null   object \n",
      " 31  locked                         2000 non-null   bool   \n",
      " 32  media_only                     2000 non-null   bool   \n",
      " 33  no_follow                      2000 non-null   bool   \n",
      " 34  num_comments                   2000 non-null   int64  \n",
      " 35  num_crossposts                 2000 non-null   int64  \n",
      " 36  over_18                        2000 non-null   bool   \n",
      " 37  parent_whitelist_status        2000 non-null   object \n",
      " 38  permalink                      2000 non-null   object \n",
      " 39  pinned                         2000 non-null   bool   \n",
      " 40  pwls                           2000 non-null   int64  \n",
      " 41  retrieved_on                   2000 non-null   int64  \n",
      " 42  score                          2000 non-null   int64  \n",
      " 43  selftext                       1999 non-null   object \n",
      " 44  send_replies                   2000 non-null   bool   \n",
      " 45  spoiler                        2000 non-null   bool   \n",
      " 46  stickied                       2000 non-null   bool   \n",
      " 47  subreddit                      2000 non-null   object \n",
      " 48  subreddit_id                   2000 non-null   object \n",
      " 49  subreddit_subscribers          2000 non-null   int64  \n",
      " 50  subreddit_type                 2000 non-null   object \n",
      " 51  thumbnail                      2000 non-null   object \n",
      " 52  title                          2000 non-null   object \n",
      " 53  total_awards_received          2000 non-null   int64  \n",
      " 54  treatment_tags                 2000 non-null   object \n",
      " 55  upvote_ratio                   2000 non-null   float64\n",
      " 56  url                            2000 non-null   object \n",
      " 57  whitelist_status               2000 non-null   object \n",
      " 58  wls                            2000 non-null   int64  \n",
      " 59  post_hint                      543 non-null    object \n",
      " 60  preview                        543 non-null    object \n",
      " 61  author_flair_background_color  71 non-null     object \n",
      " 62  author_flair_text_color        106 non-null    object \n",
      " 63  suggested_sort                 37 non-null     object \n",
      " 64  removed_by_category            186 non-null    object \n",
      " 65  thumbnail_height               540 non-null    float64\n",
      " 66  thumbnail_width                540 non-null    float64\n",
      " 67  url_overridden_by_dest         534 non-null    object \n",
      " 68  media                          50 non-null     object \n",
      " 69  media_embed                    50 non-null     object \n",
      " 70  secure_media                   50 non-null     object \n",
      " 71  secure_media_embed             50 non-null     object \n",
      " 72  author_flair_template_id       35 non-null     object \n",
      " 73  gallery_data                   63 non-null     object \n",
      " 74  is_gallery                     65 non-null     object \n",
      " 75  media_metadata                 86 non-null     object \n",
      " 76  author_cakeday                 6 non-null      object \n",
      " 77  distinguished                  20 non-null     object \n",
      " 78  banned_by                      1 non-null      object \n",
      " 79  call_to_action                 1 non-null      object \n",
      " 80  category                       1 non-null      object \n",
      "dtypes: bool(20), float64(3), int64(9), object(49)\n",
      "memory usage: 992.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "coffee = my_webscraper(subreddit='coffee')\n",
    "print(coffee.shape)\n",
    "print(coffee.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e659b21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is iteration no. 1, status code is 200, accumulated no. of rows extracted is 100.\n",
      "This is iteration no. 2, status code is 200, accumulated no. of rows extracted is 198.\n",
      "This is iteration no. 3, status code is 200, accumulated no. of rows extracted is 298.\n",
      "This is iteration no. 4, status code is 200, accumulated no. of rows extracted is 398.\n",
      "This is iteration no. 5, status code is 200, accumulated no. of rows extracted is 498.\n",
      "This is iteration no. 6, status code is 200, accumulated no. of rows extracted is 597.\n",
      "This is iteration no. 7, status code is 200, accumulated no. of rows extracted is 697.\n",
      "This is iteration no. 8, status code is 200, accumulated no. of rows extracted is 797.\n",
      "This is iteration no. 9, status code is 200, accumulated no. of rows extracted is 897.\n",
      "This is iteration no. 10, status code is 200, accumulated no. of rows extracted is 996.\n",
      "This is iteration no. 11, status code is 200, accumulated no. of rows extracted is 1096.\n",
      "This is iteration no. 12, status code is 200, accumulated no. of rows extracted is 1195.\n",
      "This is iteration no. 13, status code is 200, accumulated no. of rows extracted is 1295.\n",
      "This is iteration no. 14, status code is 200, accumulated no. of rows extracted is 1395.\n",
      "This is iteration no. 15, status code is 200, accumulated no. of rows extracted is 1495.\n",
      "This is iteration no. 16, status code is 200, accumulated no. of rows extracted is 1595.\n",
      "This is iteration no. 17, status code is 200, accumulated no. of rows extracted is 1695.\n",
      "This is iteration no. 18, status code is 200, accumulated no. of rows extracted is 1794.\n",
      "This is iteration no. 19, status code is 200, accumulated no. of rows extracted is 1894.\n",
      "This is iteration no. 20, status code is 200, accumulated no. of rows extracted is 1994.\n",
      "(1994, 83)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1994 entries, 0 to 1993\n",
      "Data columns (total 83 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   all_awardings                  1994 non-null   object \n",
      " 1   allow_live_comments            1994 non-null   bool   \n",
      " 2   author                         1994 non-null   object \n",
      " 3   author_flair_css_class         0 non-null      object \n",
      " 4   author_flair_richtext          1985 non-null   object \n",
      " 5   author_flair_text              35 non-null     object \n",
      " 6   author_flair_type              1985 non-null   object \n",
      " 7   author_fullname                1985 non-null   object \n",
      " 8   author_is_blocked              1994 non-null   bool   \n",
      " 9   author_patreon_flair           1985 non-null   object \n",
      " 10  author_premium                 1985 non-null   object \n",
      " 11  awarders                       1994 non-null   object \n",
      " 12  can_mod_post                   1994 non-null   bool   \n",
      " 13  contest_mode                   1994 non-null   bool   \n",
      " 14  created_utc                    1994 non-null   int64  \n",
      " 15  domain                         1994 non-null   object \n",
      " 16  full_link                      1994 non-null   object \n",
      " 17  gildings                       1994 non-null   object \n",
      " 18  id                             1994 non-null   object \n",
      " 19  is_created_from_ads_ui         1994 non-null   bool   \n",
      " 20  is_crosspostable               1994 non-null   bool   \n",
      " 21  is_meta                        1994 non-null   bool   \n",
      " 22  is_original_content            1994 non-null   bool   \n",
      " 23  is_reddit_media_domain         1994 non-null   bool   \n",
      " 24  is_robot_indexable             1994 non-null   bool   \n",
      " 25  is_self                        1994 non-null   bool   \n",
      " 26  is_video                       1994 non-null   bool   \n",
      " 27  link_flair_background_color    1891 non-null   object \n",
      " 28  link_flair_css_class           1482 non-null   object \n",
      " 29  link_flair_richtext            1994 non-null   object \n",
      " 30  link_flair_template_id         1188 non-null   object \n",
      " 31  link_flair_text                1482 non-null   object \n",
      " 32  link_flair_text_color          1991 non-null   object \n",
      " 33  link_flair_type                1994 non-null   object \n",
      " 34  locked                         1994 non-null   bool   \n",
      " 35  media_only                     1994 non-null   bool   \n",
      " 36  no_follow                      1994 non-null   bool   \n",
      " 37  num_comments                   1994 non-null   int64  \n",
      " 38  num_crossposts                 1994 non-null   int64  \n",
      " 39  over_18                        1994 non-null   bool   \n",
      " 40  parent_whitelist_status        1994 non-null   object \n",
      " 41  permalink                      1994 non-null   object \n",
      " 42  pinned                         1994 non-null   bool   \n",
      " 43  post_hint                      806 non-null    object \n",
      " 44  preview                        806 non-null    object \n",
      " 45  pwls                           1994 non-null   int64  \n",
      " 46  retrieved_on                   1994 non-null   int64  \n",
      " 47  score                          1994 non-null   int64  \n",
      " 48  selftext                       1991 non-null   object \n",
      " 49  send_replies                   1994 non-null   bool   \n",
      " 50  spoiler                        1994 non-null   bool   \n",
      " 51  stickied                       1994 non-null   bool   \n",
      " 52  subreddit                      1994 non-null   object \n",
      " 53  subreddit_id                   1994 non-null   object \n",
      " 54  subreddit_subscribers          1994 non-null   int64  \n",
      " 55  subreddit_type                 1994 non-null   object \n",
      " 56  thumbnail                      1994 non-null   object \n",
      " 57  thumbnail_height               979 non-null    float64\n",
      " 58  thumbnail_width                979 non-null    float64\n",
      " 59  title                          1994 non-null   object \n",
      " 60  total_awards_received          1994 non-null   int64  \n",
      " 61  treatment_tags                 1994 non-null   object \n",
      " 62  upvote_ratio                   1994 non-null   float64\n",
      " 63  url                            1994 non-null   object \n",
      " 64  url_overridden_by_dest         980 non-null    object \n",
      " 65  whitelist_status               1994 non-null   object \n",
      " 66  wls                            1994 non-null   int64  \n",
      " 67  removed_by_category            411 non-null    object \n",
      " 68  author_flair_background_color  19 non-null     object \n",
      " 69  author_flair_text_color        50 non-null     object \n",
      " 70  banned_by                      3 non-null      object \n",
      " 71  gallery_data                   208 non-null    object \n",
      " 72  is_gallery                     242 non-null    object \n",
      " 73  media_metadata                 224 non-null    object \n",
      " 74  author_cakeday                 9 non-null      object \n",
      " 75  media                          36 non-null     object \n",
      " 76  media_embed                    36 non-null     object \n",
      " 77  secure_media                   36 non-null     object \n",
      " 78  secure_media_embed             36 non-null     object \n",
      " 79  crosspost_parent               42 non-null     object \n",
      " 80  crosspost_parent_list          42 non-null     object \n",
      " 81  author_flair_template_id       32 non-null     object \n",
      " 82  poll_data                      14 non-null     object \n",
      "dtypes: bool(20), float64(3), int64(9), object(51)\n",
      "memory usage: 1020.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "tea = my_webscraper(subreddit='tea')\n",
    "print(tea.shape)\n",
    "print(tea.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b256fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract dfs to csv to work with in notebook2\n",
    "# files have been saved in the data folder; commenting this out in case we overwrite the data which is extracted live...\n",
    "\n",
    "# coffee.to_csv('./data/coffee.csv',index=False,na_rep=' ')\n",
    "# tea.to_csv('./data/tea.csv',index=False,na_rep=' ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
